{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d81461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "assert X_train.shape == (60000, 28, 28)\n",
    "assert X_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)\n",
    "\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "X_val = X_train[50000:]\n",
    "y_val = y_train[50000:]\n",
    "\n",
    "X_train = X_train[:50000]\n",
    "y_train = y_train[:50000]\n",
    "\n",
    "assert X_train.shape == (50000, 28, 28)\n",
    "assert y_train.shape == (50000,)\n",
    "assert X_val.shape == (10000, 28, 28)\n",
    "assert y_val.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d0b436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_datasets(X, y):\n",
    "    \"\"\"\n",
    "    Split dataset into:\n",
    "    A: samples excluding classes 6 and 7\n",
    "    B: samples of only classes 6 and 7, converted to binary labels\n",
    "    \"\"\"\n",
    "    maskB = (y == 6) | (y == 7)\n",
    "    maskA = ~maskB\n",
    "\n",
    "    XA, yA = X[maskA], y[maskA]\n",
    "    XB, yB = X[maskB], y[maskB]\n",
    "\n",
    "    # Update labels for A: remove classes 6 and 7\n",
    "    yA = yA.copy()\n",
    "    yA[yA > 7] -= 2\n",
    "\n",
    "    # Update labels for B: convert to binary (0 for class 7, 1 for class 6)\n",
    "    yB = (yB == 6).astype(np.float32)\n",
    "    return (XA, yA), (XB, yB)\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_datasets(X_train, y_train)\n",
    "(X_val_A, y_val_A), (X_val_B, y_val_B) = split_datasets(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86c7c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2225 - val_accuracy: 0.9194 - val_loss: 0.2441\n",
      "Epoch 2/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2161 - val_accuracy: 0.9172 - val_loss: 0.2426\n",
      "Epoch 3/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2156 - val_accuracy: 0.9198 - val_loss: 0.2389\n",
      "Epoch 4/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2203 - val_accuracy: 0.9188 - val_loss: 0.2400\n",
      "Epoch 5/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2127 - val_accuracy: 0.9183 - val_loss: 0.2394\n",
      "Epoch 6/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2160 - val_accuracy: 0.9186 - val_loss: 0.2386\n",
      "Epoch 7/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2120 - val_accuracy: 0.9211 - val_loss: 0.2326\n",
      "Epoch 8/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2080 - val_accuracy: 0.9215 - val_loss: 0.2334\n",
      "Epoch 9/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.2083 - val_accuracy: 0.9221 - val_loss: 0.2305\n",
      "Epoch 10/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.2047 - val_accuracy: 0.9198 - val_loss: 0.2365\n",
      "Epoch 11/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.2012 - val_accuracy: 0.9233 - val_loss: 0.2288\n",
      "Epoch 12/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 0.9327 - loss: 0.2007 - val_accuracy: 0.9230 - val_loss: 0.2293\n",
      "Epoch 13/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.2006 - val_accuracy: 0.9205 - val_loss: 0.2297\n",
      "Epoch 14/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9330 - loss: 0.1982 - val_accuracy: 0.9230 - val_loss: 0.2271\n",
      "Epoch 15/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9322 - loss: 0.1985 - val_accuracy: 0.9225 - val_loss: 0.2273\n",
      "Epoch 16/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9326 - loss: 0.1976 - val_accuracy: 0.9216 - val_loss: 0.2270\n",
      "Epoch 17/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9322 - loss: 0.1975 - val_accuracy: 0.9232 - val_loss: 0.2226\n",
      "Epoch 18/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9340 - loss: 0.1949 - val_accuracy: 0.9254 - val_loss: 0.2209\n",
      "Epoch 19/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9373 - loss: 0.1882 - val_accuracy: 0.9227 - val_loss: 0.2219\n",
      "Epoch 20/20\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.1959 - val_accuracy: 0.9211 - val_loss: 0.2281\n",
      "[0.9247088432312012, 0.9255103468894958, 0.9256105422973633, 0.9262366890907288, 0.9264370799064636, 0.9279148578643799, 0.9285159707069397, 0.9292423129081726, 0.929993748664856, 0.9310457110404968, 0.9304696321487427, 0.9318972826004028, 0.9314715266227722, 0.9326487183570862, 0.9327989816665649, 0.9332999587059021, 0.9337758421897888, 0.9344521164894104, 0.9349530339241028, 0.9349530339241028]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "from keras import optimizers\n",
    "\n",
    "new_training = False\n",
    "if new_training:\n",
    "    modelA = models.Sequential()\n",
    "    modelA.add(layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # add 5 hidden layers\n",
    "    for n in [300, 100, 50, 50, 50]:\n",
    "        modelA.add(layers.Dense(n, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "\n",
    "    modelA.add(layers.Dense(8, activation=\"softmax\"))\n",
    "    # modelA.summary()\n",
    "    # utils.plot_model(modelA, show_shapes=True)\n",
    "\n",
    "    modelA.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=optimizers.SGD(learning_rate=1e-3),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    epoch = 20\n",
    "    H = modelA.fit(X_train_A, y_train_A, epochs=epoch, validation_data=(X_val_A, y_val_A))\n",
    "    history = H.history\n",
    "\n",
    "    joblib.dump(history, \"histories/transfer_learning\")\n",
    "    modelA.save(\"models/transfer_learning.keras\")\n",
    "else:\n",
    "    history = joblib.load(\"histories/transfer_learning\")\n",
    "    modelA = models.load_model(\"models/transfer_learning.keras\")\n",
    "    # print(modelA.summary())\n",
    "    # modelA.compile(\n",
    "    #     loss=\"sparse_categorical_crossentropy\",\n",
    "    #     optimizer=optimizers.SGD(learning_rate=1e-3),\n",
    "    #     metrics=[\"accuracy\"],\n",
    "    # )\n",
    "    epoch = 20\n",
    "    H = modelA.fit(X_train_A, y_train_A, epochs=epoch, validation_data=(X_val_A, y_val_A))\n",
    "    history = H.history\n",
    "    \n",
    "    print(history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d77f4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0602 - val_accuracy: 0.9990 - val_loss: 0.0187\n",
      "Epoch 2/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9989 - loss: 0.0169 - val_accuracy: 0.9990 - val_loss: 0.0115\n",
      "Epoch 3/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9994 - loss: 0.0103 - val_accuracy: 0.9990 - val_loss: 0.0087\n",
      "Epoch 4/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9993 - loss: 0.0088 - val_accuracy: 0.9995 - val_loss: 0.0072\n",
      "Epoch 5/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.9989 - loss: 0.0087 - val_accuracy: 0.9995 - val_loss: 0.0063\n",
      "Epoch 6/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9993 - loss: 0.0061 - val_accuracy: 0.9995 - val_loss: 0.0056\n",
      "Epoch 7/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9988 - loss: 0.0061 - val_accuracy: 0.9995 - val_loss: 0.0052\n",
      "Epoch 8/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9995 - val_loss: 0.0048\n",
      "Epoch 9/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9993 - loss: 0.0042 - val_accuracy: 0.9995 - val_loss: 0.0045\n",
      "Epoch 10/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.9995 - val_loss: 0.0043\n",
      "Epoch 11/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9994 - loss: 0.0040 - val_accuracy: 0.9995 - val_loss: 0.0041\n",
      "Epoch 12/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9995 - val_loss: 0.0039\n",
      "Epoch 13/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9995 - val_loss: 0.0038\n",
      "Epoch 14/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 0.9995 - val_loss: 0.0036\n",
      "Epoch 15/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.9995 - val_loss: 0.0035\n",
      "Epoch 16/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.9995 - val_loss: 0.0034\n",
      "Epoch 17/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9995 - val_loss: 0.0033\n",
      "Epoch 18/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.9995 - val_loss: 0.0032\n",
      "Epoch 19/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9995 - val_loss: 0.0032\n",
      "Epoch 20/20\n",
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.9995 - val_loss: 0.0031\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from keras import models\n",
    "\n",
    "modelA = models.load_model(\"models/transfer_learning.keras\")\n",
    "\n",
    "modelB = models.Sequential(modelA.layers[:-1])\n",
    "modelB.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "for layer in modelB.layers[:2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "modelB.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=optimizers.SGD(learning_rate=1e-3),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "H = modelB.fit(X_train_B, y_train_B, epochs=epoch, validation_data=(X_val_B, y_val_B))\n",
    "history = H.history\n",
    "\n",
    "joblib.dump(history, \"histories/transfer_learning_binary\")\n",
    "modelB.save(\"models/transfer_learning_binary.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
