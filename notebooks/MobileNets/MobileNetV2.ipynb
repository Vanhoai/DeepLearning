{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce644f8",
   "metadata": {},
   "source": [
    "#### Implementation of MobileNetV2 architecture using PyTorch\n",
    "Paper: [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381)\n",
    "\n",
    "MobileNetV2 is an improved version of MobileNetV1, which introduces the concept of inverted residuals and linear bottlenecks. It uses depthwise separable convolutions and introduces a new block called the inverted residual block.\n",
    "\n",
    "##### Components of MobileNetV2:\n",
    "1. **Inverted Residual Block**: A residual block where the number of channels is expanded first, then reduced (inverted from traditional ResNet).\n",
    "2. **Linear Bottleneck**: The final layer of the block uses a linear activation function instead of ReLU to avoid non-linearity in the bottleneck layer.\n",
    "3. **Depthwise Separable Convolution**: Similar to MobileNetV1, it uses depthwise separable convolutions to reduce the number of parameters and computations.\n",
    "4. **Skip Connections**: Similar to ResNet, it uses skip connections to allow gradients to flow through the network more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935a45c",
   "metadata": {},
   "source": [
    "Depthwise Separable Convolution is a key component of MobileNetV2, which consists of two layers:\n",
    "- Depthwise Convolution: Applies a single filter to each input channel.\n",
    "- Pointwise Convolution: A 1x1 convolution that combines the outputs of the depthwise convolution.\n",
    "\n",
    "Linear Bottleneck is used in the final layer of the inverted residual block to reduce the number of parameters and computations while maintaining performance.\n",
    "\n",
    "Inverted Residual Block:\n",
    "- Original residual block contains an input followed by several bottlenecks then followed by expansion and the shortcuts exist between thick layers (layers with many channels).\n",
    "- However, inspired by the intuition that the bottlenecks actually contain all the necessary information and expansion layer acts merely as a non-linear transformation, MobileNetV2 uses shortcuts directly between the bottlenecks (thin layers). Hatched layers use linear activation.\n",
    "- ReLU6 is used as the non-liner activation because of its robustness when used with low-precision computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70392f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        hidden_dim = int(in_channels * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            # 1. Expansion (Conv 1x1) -> only change channels\n",
    "            layers.append(nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(hidden_dim))\n",
    "            layers.append(nn.ReLU6(inplace=True))\n",
    "        \n",
    "        # 2. Depthwise Convolution\n",
    "        layers.append(nn.Conv2d(\n",
    "            in_channels=hidden_dim, \n",
    "            out_channels=hidden_dim,\n",
    "            kernel_size=3, \n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            groups=hidden_dim,\n",
    "            bias=False\n",
    "        ))\n",
    "        layers.append(nn.BatchNorm2d(hidden_dim))\n",
    "        layers.append(nn.ReLU6(inplace=True))\n",
    "\n",
    "        # 3. Projection (Conv 1x1, no activation)\n",
    "        layers.append(nn.Conv2d(hidden_dim, out_channels=out_channels, kernel_size=1, bias=False))\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.use_res_connect:\n",
    "            return x + self.block(x)\n",
    "        else:\n",
    "            return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "    \n",
    "        # (t, c, n, s): (expand_ratio, out_channels, num_blocks, stride)\n",
    "        self.configs = [\n",
    "            (1, 16, 1, 1),\n",
    "            (6, 24, 2, 2),\n",
    "            (6, 32, 3, 2),\n",
    "            (6, 64, 4, 2),\n",
    "            (6, 96, 3, 1),\n",
    "            (6, 160, 3, 2),\n",
    "            (6, 320, 1, 1),\n",
    "        ]\n",
    "\n",
    "        # initial layer\n",
    "        input_channels = 32\n",
    "        layers = [\n",
    "            nn.Conv2d(3, input_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        ]\n",
    "\n",
    "        # Inverted Residual blocks\n",
    "        for t, c, n, s in self.configs:\n",
    "            output_channel = c\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                layers.append(InvertedResidual(input_channels, output_channel, stride, t))\n",
    "                input_channels = output_channel\n",
    "\n",
    "        # Final Conv 1x1\n",
    "        last_channel = 1280\n",
    "        layers.append(nn.Conv2d(input_channels, last_channel, kernel_size=1, bias=False))\n",
    "        layers.append(nn.BatchNorm2d(last_channel))\n",
    "        layers.append(nn.ReLU6(inplace=True))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(last_channel, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)  # output: [B, 1280, 1, 1]\n",
    "        x = x.view(x.size(0), -1)  # flatten to [B, 1280]\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29188486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MobileNetV2                              [1, 1000]                 --\n",
       "├─Sequential: 1-1                        [1, 1280, 7, 7]           --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 112, 112]         864\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 112, 112]         64\n",
       "│    └─ReLU6: 2-3                        [1, 32, 112, 112]         --\n",
       "│    └─InvertedResidual: 2-4             [1, 16, 112, 112]         --\n",
       "│    │    └─Sequential: 3-1              [1, 16, 112, 112]         896\n",
       "│    └─InvertedResidual: 2-5             [1, 24, 56, 56]           --\n",
       "│    │    └─Sequential: 3-2              [1, 24, 56, 56]           5,136\n",
       "│    └─InvertedResidual: 2-6             [1, 24, 56, 56]           --\n",
       "│    │    └─Sequential: 3-3              [1, 24, 56, 56]           8,832\n",
       "│    └─InvertedResidual: 2-7             [1, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-4              [1, 32, 28, 28]           10,000\n",
       "│    └─InvertedResidual: 2-8             [1, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-5              [1, 32, 28, 28]           14,848\n",
       "│    └─InvertedResidual: 2-9             [1, 32, 28, 28]           --\n",
       "│    │    └─Sequential: 3-6              [1, 32, 28, 28]           14,848\n",
       "│    └─InvertedResidual: 2-10            [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-7              [1, 64, 14, 14]           21,056\n",
       "│    └─InvertedResidual: 2-11            [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-8              [1, 64, 14, 14]           54,272\n",
       "│    └─InvertedResidual: 2-12            [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-9              [1, 64, 14, 14]           54,272\n",
       "│    └─InvertedResidual: 2-13            [1, 64, 14, 14]           --\n",
       "│    │    └─Sequential: 3-10             [1, 64, 14, 14]           54,272\n",
       "│    └─InvertedResidual: 2-14            [1, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-11             [1, 96, 14, 14]           66,624\n",
       "│    └─InvertedResidual: 2-15            [1, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-12             [1, 96, 14, 14]           118,272\n",
       "│    └─InvertedResidual: 2-16            [1, 96, 14, 14]           --\n",
       "│    │    └─Sequential: 3-13             [1, 96, 14, 14]           118,272\n",
       "│    └─InvertedResidual: 2-17            [1, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-14             [1, 160, 7, 7]            155,264\n",
       "│    └─InvertedResidual: 2-18            [1, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-15             [1, 160, 7, 7]            320,000\n",
       "│    └─InvertedResidual: 2-19            [1, 160, 7, 7]            --\n",
       "│    │    └─Sequential: 3-16             [1, 160, 7, 7]            320,000\n",
       "│    └─InvertedResidual: 2-20            [1, 320, 7, 7]            --\n",
       "│    │    └─Sequential: 3-17             [1, 320, 7, 7]            473,920\n",
       "│    └─Conv2d: 2-21                      [1, 1280, 7, 7]           409,600\n",
       "│    └─BatchNorm2d: 2-22                 [1, 1280, 7, 7]           2,560\n",
       "│    └─ReLU6: 2-23                       [1, 1280, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-2                 [1, 1280, 1, 1]           --\n",
       "├─Linear: 1-3                            [1, 1000]                 1,281,000\n",
       "==========================================================================================\n",
       "Total params: 3,504,872\n",
       "Trainable params: 3,504,872\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 300.81\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 106.86\n",
       "Params size (MB): 14.02\n",
       "Estimated Total Size (MB): 121.48\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = MobileNetV2(num_classes=1000)\n",
    "x = torch.randn(1, 3, 224, 224)  # dummy input\n",
    "out = model(x)\n",
    "print(out.shape)  # -> torch.Size([1, 1000])\n",
    "\n",
    "summary(model, input_size=(1, 3, 224, 224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
